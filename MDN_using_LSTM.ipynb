{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7iHcu3u8swkS"
   },
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6jVSOcMms2UD"
   },
   "outputs": [],
   "source": [
    "dataset = pd.read_csv('Load Profile & DSM.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 461
    },
    "id": "Nx8_htR9tFAr",
    "outputId": "f82202df-ba68-4137-b97f-3d03d29831aa"
   },
   "outputs": [],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cigT_jaeVxuD",
    "outputId": "b98ac393-ab6b-4f29-e6e3-1e5b70e4c01a"
   },
   "outputs": [],
   "source": [
    "# Initialize an empty list to store extracted values\n",
    "load = []\n",
    "scheduled = []\n",
    "ODUD = []\n",
    "# Iterate over every third column (starting from the second column)\n",
    "for col_idx1 in range(1, dataset.shape[1], 3):\n",
    "    # Extract values from the current column, starting from the fourth row\n",
    "    column_values1 = dataset.iloc[2:, col_idx1].values.tolist()\n",
    "    # Append the extracted values to the list\n",
    "    load.extend(column_values1)\n",
    "\n",
    "load = np.array(load)\n",
    "\n",
    "print(\"Shape of load:\", load.shape)\n",
    "print(load)\n",
    "\n",
    "for col_idx2 in range(2, dataset.shape[1], 3):\n",
    "    column_values2 = dataset.iloc[2:, col_idx2].values.tolist()\n",
    "    scheduled.extend(column_values2)\n",
    "scheduled = np.array(scheduled)\n",
    "\n",
    "print(\"Shape of scheduled:\",scheduled.shape)\n",
    "print(scheduled)\n",
    "\n",
    "for col_idx3 in range(3, dataset.shape[1], 3):\n",
    "    column_values3 = dataset.iloc[2:, col_idx3].values.tolist()\n",
    "    ODUD.extend(column_values3)\n",
    "ODUD = np.array(ODUD)\n",
    "\n",
    "print(\"Shape of ODUD:\",ODUD.shape)\n",
    "print(ODUD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yh-MxOD7Pm-Q",
    "outputId": "06b6c403-7678-4a78-be86-95784b46e0c1"
   },
   "outputs": [],
   "source": [
    "load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Jr_mjNAAUKeX",
    "outputId": "b47ef42d-35d2-4e95-a129-1d9b368677e9"
   },
   "outputs": [],
   "source": [
    "data_numeric = pd.to_numeric(load, errors='coerce')\n",
    "load=np.array(load, dtype=float)\n",
    "data_numeric = pd.to_numeric(scheduled, errors='coerce')\n",
    "scheduled=np.array(scheduled, dtype=float)\n",
    "data_numeric = pd.to_numeric(ODUD, errors='coerce')\n",
    "ODUD=np.array(ODUD, dtype=float)\n",
    "# Check the data type after conversion\n",
    "print(load.dtype)\n",
    "print(scheduled)\n",
    "load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hFZ0Q6tKPdGA",
    "outputId": "642e8c4c-ac07-44c9-b6e6-9215522fb46b"
   },
   "outputs": [],
   "source": [
    "load[0:96].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "08ZGWhBVy9vg",
    "outputId": "1ae8bdb3-f0dc-4f4c-86fd-6c1044c181ae"
   },
   "outputs": [],
   "source": [
    "\n",
    "df = pd.DataFrame({'Load': load, 'Scheduled': scheduled, 'OD/UD': ODUD})\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LInbrC4iI-mA",
    "outputId": "11d1be8a-2869-45d1-c505-1d953459dec2"
   },
   "outputs": [],
   "source": [
    "missing_values = df.isnull().sum()\n",
    "print(\"Missing Values:\")\n",
    "print(missing_values)\n",
    "#print(len(missing_values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "UMwJQ09fdk_f",
    "outputId": "b03938f2-fdea-470f-b028-b9cf29b10413"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Your original DataFrame (df) with Load, Scheduled, and OD/UD columns\n",
    "# Assuming df is already defined\n",
    "\n",
    "# Define the start and end dates\n",
    "start_date = '2022-04-01 00:00:00'\n",
    "end_date = '2023-03-31 00:00:00'\n",
    "\n",
    "# Create a DatetimeIndex with 15-minute frequency\n",
    "date_range = pd.date_range(start=start_date, end=end_date, freq='15T')\n",
    "\n",
    "# Create a DataFrame with the dates\n",
    "df_dates = pd.DataFrame({'timestamp': date_range})\n",
    "\n",
    "# Change the format of the timestamp to day-month-2023\n",
    "df_dates['timestamp'] = df_dates['timestamp'].dt.strftime('%d-%m-%Y %H:%M:%S')\n",
    "\n",
    "# Insert the timestamp column at the beginning of the DataFrame\n",
    "df.insert(0, 'timestamp', df_dates['timestamp'])\n",
    "\n",
    "# Display the updated DataFrame\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0V6T93ugQCb5"
   },
   "outputs": [],
   "source": [
    "df.to_csv('data_extraction.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5Wi5MOrKTa0c"
   },
   "outputs": [],
   "source": [
    "# from google.colab import files\n",
    "\n",
    "# output_csv_path = 'arhf.csv'\n",
    "\n",
    "# files.download(output_csv_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ygmSmaobsAbk",
    "outputId": "02349164-2966-457a-e5d8-b990605619c8"
   },
   "outputs": [],
   "source": [
    "\n",
    "df['timestamp'] = pd.to_datetime(df['timestamp'], format='%d-%m-%Y %H:%M:%S')\n",
    "\n",
    "weekday_dummies = pd.get_dummies(df['timestamp'].dt.dayofweek, prefix='weekday')\n",
    "\n",
    "weekday_dummies.columns = ['weekday_' + str((i + 1) % 7) for i in range(7)]\n",
    "\n",
    "df = pd.concat([df, weekday_dummies], axis=1)\n",
    "#df.drop(columns=['timestamp'], inplace=True)\n",
    "\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 399
    },
    "id": "12srcH_LrhkN",
    "outputId": "baad4176-1615-47f6-dcd5-e0a33229820f"
   },
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 790
    },
    "id": "z-Gr5Hh-x31D",
    "outputId": "60bb13d5-8a14-4395-cda0-e0b660c08556"
   },
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Q65w_fz81Y1j",
    "outputId": "44ae2223-48fe-4e61-caf1-98c03639f45b"
   },
   "outputs": [],
   "source": [
    "\n",
    "lag96 = np.zeros([len(load),])\n",
    "lag96[96:len(load)]=load[0:len(load)-96]\n",
    "print(lag96)\n",
    "print(lag96.shape)\n",
    "\n",
    "lag192 = np.zeros([len(load),])\n",
    "lag192[96*2:len(load)]=load[0:len(load)-96*2]\n",
    "print(lag192)\n",
    "print(lag192.shape)\n",
    "\n",
    "lag672 = np.zeros([len(load),])\n",
    "lag672[96*7:len(load)]=load[0:len(load)-96*7]\n",
    "print(lag672)\n",
    "print(lag672.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BPLadL6O9h0e"
   },
   "outputs": [],
   "source": [
    "df['Lag96'] = lag96\n",
    "df['Lag192'] = lag192\n",
    "df['Lag672'] = lag672"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 790
    },
    "id": "eojxBNbH9hxq",
    "outputId": "9c2a4b4e-f93a-4184-c2c8-cf1d8be3ac35"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mdf\u001b[49m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BPmR7N7xXSBn"
   },
   "outputs": [],
   "source": [
    "#df.to_csv('Predictive_matrix.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tx5Jdn-Yawt-"
   },
   "outputs": [],
   "source": [
    "time=df.iloc[:,0].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9US-SEKVbBR0",
    "outputId": "f45a8ed8-aeba-4426-c1c3-c6bb809acfc1"
   },
   "outputs": [],
   "source": [
    "n = len(time) - 960\n",
    "\n",
    "time_some = time[:n]\n",
    "time_remaining = time[n:]\n",
    "\n",
    "print(\"time_some shape:\", time_some.shape)\n",
    "print(\"time_remaining shape:\", time_remaining.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HKyxsS4k9hsv"
   },
   "outputs": [],
   "source": [
    "X = df.iloc[:, 4:].values\n",
    "y = df.iloc[:,1].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QRjVIM1FbrfE"
   },
   "outputs": [],
   "source": [
    "z = df.iloc[:,2].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "s4oXBWQSaRwz",
    "outputId": "b020d55c-622c-436b-b926-2e4800fa7e5e"
   },
   "outputs": [],
   "source": [
    "\n",
    "n = len(z) - 960\n",
    "\n",
    "z_some = z[:n]\n",
    "z_remaining = z[n:]\n",
    "\n",
    "print(\"z_some shape:\", z_some.shape)\n",
    "print(\"z_remaining shape:\", z_remaining.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dixRl0QybyJw",
    "outputId": "7e88023d-6970-49eb-df5a-477bdc3ea65b"
   },
   "outputs": [],
   "source": [
    "z_some"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "q86W3EyHIZuR",
    "outputId": "e3e32aaf-a7bd-48d7-907b-0592cc1ceac4"
   },
   "outputs": [],
   "source": [
    "# Get the names of columns for X\n",
    "X_columns = df.columns[4:]\n",
    "\n",
    "# Get the name of the column for y\n",
    "y_column = df.columns[1]\n",
    "\n",
    "print(\"Columns for X:\", X_columns)\n",
    "print(\"Column for y:\", y_column)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "v_e_UvjaHqJv",
    "outputId": "bdee6958-b16f-4874-a336-7fdd88dfdbe6"
   },
   "outputs": [],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PmuIJ82LIh6X"
   },
   "source": [
    "Splitting the dataset into the Training set and Test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WFza6rZrW4Og"
   },
   "outputs": [],
   "source": [
    "training_set = df.iloc[:, 1].values\n",
    "# training_set=training_set.reshape(-1,1)\n",
    "# training_set.shape\n",
    "# Feature Scaling\n",
    "# from sklearn.preprocessing import MinMaxScaler\n",
    "# sc = MinMaxScaler(feature_range = (0, 1))\n",
    "# training_set_scaled = sc.fit_transform(training_set)\n",
    "training_set=training_set.reshape(-1,1)\n",
    "# Creating a data structure with 60 timesteps and 1 output\n",
    "X_train = []\n",
    "y_train = []\n",
    "for i in range(7, 31776):\n",
    "    X_train.append(training_set[i-7:i, 0])\n",
    "    y_train.append(training_set[i, 0])\n",
    "X_train\n",
    "X_train, y_train = np.array(X_train), np.array(y_train)\n",
    "X_train.shape\n",
    "y_train.shape\n",
    "# Reshaping\n",
    "X_train = np.reshape(X_train, (X_train.shape[0], X_train.shape[1], 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jEx_XvjEX6sw",
    "outputId": "074fad49-cd6a-43bb-d5eb-c76510378436"
   },
   "outputs": [],
   "source": [
    "y_train.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ZitIOZDbXxc7",
    "outputId": "c65a07e7-b374-4f87-b325-31c6da7b1a68"
   },
   "outputs": [],
   "source": [
    "X_train.shape\n",
    "# y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YMzc_gt3EWBO",
    "outputId": "e95d99a9-e13e-4c1b-c70a-a073ed9dfdf0"
   },
   "outputs": [],
   "source": [
    "\n",
    "m = len(time) - 960\n",
    "\n",
    "load_train = load[:m]\n",
    "load_test = load[m:]\n",
    "\n",
    "print(\"Load_train shape:\",load_train.shape)\n",
    "print(\"Load_test shape:\", load_test.shape)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "load_test = load_test.reshape(-1,1)\n",
    "\n",
    "X_test = []\n",
    "y_test = []\n",
    "for i in range(7, 960):\n",
    "    X_test.append(load_test[i-7:i, 0])\n",
    "    y_test.append(load_test[i, 0])\n",
    "X_test, y_test = np.array(X_test), np.array(y_test)\n",
    "X_test = np.reshape(X_test, (X_test.shape[0], X_test.shape[1], 1))\n",
    "X_test.shape\n",
    "y_test.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bNDXRiCSZmN1"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VRCL6iBjZmK0"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "B3twXfq3lb1M"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HuyG3_KPZmHc"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_probability as tfp\n",
    "import keras\n",
    "from tensorflow_probability import distributions as tfd\n",
    "from tensorflow.keras.layers import Input, Dense, Activation, Concatenate\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense\n",
    "from sklearn.model_selection import train_test_split\n",
    "keras.backend.clear_session()\n",
    "\n",
    "import matplotlib.gridspec as grid_spec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QwFR0OYAEV-m"
   },
   "outputs": [],
   "source": [
    "class MDN(tf.keras.Model):\n",
    "\n",
    "    def __init__(self, neurons=100, components = 2, timesteps=7, features=1):\n",
    "        super(MDN, self).__init__(name=\"MDN\")\n",
    "        self.neurons = neurons\n",
    "        self.components = components\n",
    "\n",
    "        self.h1 = LSTM(neurons, activation='relu', input_shape=(timesteps, features))\n",
    "        self.h2 = Dense(neurons, activation=\"relu\", name=\"h2\")\n",
    "\n",
    "        self.alphas = Dense(components, activation=\"softmax\", name=\"alphas\")\n",
    "        self.mus = Dense(components, name=\"mus\")\n",
    "        self.sigmas = Dense(components, activation=\"nnelu\", name=\"sigmas\")\n",
    "        self.pvec = Concatenate(name=\"pvec\")\n",
    "\n",
    "    def call(self, inputs):\n",
    "        x = self.h1(inputs)\n",
    "        x = self.h2(x)\n",
    "\n",
    "        alpha_v = self.alphas(x)\n",
    "        mu_v = self.mus(x)\n",
    "        sigma_v = self.sigmas(x)\n",
    "\n",
    "        return self.pvec([alpha_v, mu_v, sigma_v])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1pvdDLd2EV8K"
   },
   "outputs": [],
   "source": [
    "def nnelu(input):\n",
    "    \"\"\" Computes the Non-Negative Exponential Linear Unit\n",
    "    \"\"\"\n",
    "    return tf.add(tf.constant(1, dtype=tf.float32), tf.nn.elu(input))\n",
    "\n",
    "\n",
    "tf.keras.utils.get_custom_objects().update({'nnelu': Activation(nnelu)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ycHrglxbEV5u"
   },
   "outputs": [],
   "source": [
    "def slice_parameter_vectors(parameter_vector):\n",
    "    \"\"\" Returns an unpacked list of parameter vectors.\n",
    "    \"\"\"\n",
    "    return [parameter_vector[:,i*components:(i+1)*components] for i in range(no_parameters)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "j5YVqY0rEV3M"
   },
   "outputs": [],
   "source": [
    "def gnll_loss(y, parameter_vector):\n",
    "    \"\"\" Computes the mean negative log-likelihood loss of y given the mixture parameters.\n",
    "    \"\"\"\n",
    "    alpha, mu, sigma = slice_parameter_vectors(parameter_vector) # Unpack parameter vectors\n",
    "\n",
    "    gm = tfd.MixtureSameFamily(\n",
    "        mixture_distribution=tfd.Categorical(probs=alpha),\n",
    "        components_distribution=tfd.Normal(\n",
    "            loc=mu,\n",
    "            scale=sigma))\n",
    "\n",
    "    log_likelihood = gm.log_prob(tf.transpose(y)) # Evaluate log-probability of y\n",
    "\n",
    "    return -tf.reduce_mean(log_likelihood, axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bEbJbKBnYww6",
    "outputId": "65919157-ae93-4851-f4ca-eac4008c988f"
   },
   "outputs": [],
   "source": [
    "print(y_test.shape)\n",
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NXJXDNMvaipC",
    "outputId": "2d32bd45-c28a-4c67-b13a-21e658fb2eb2"
   },
   "outputs": [],
   "source": [
    "print(\"X_train shape:\",X_train.shape)\n",
    "print(\"X_test shape:\", X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xgY5oVhlajml"
   },
   "outputs": [],
   "source": [
    "X_train = X_train.reshape((X_train.shape[0], X_train.shape[1], 1))\n",
    "X_test = X_test.reshape((X_test.shape[0], X_test.shape[1], 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GBHki96jEV0q"
   },
   "outputs": [],
   "source": [
    "no_parameters = 3\n",
    "\n",
    "components = 2\n",
    "neurons = 200\n",
    "\n",
    "opt = tf.optimizers.Adam(1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nkSFUAnzEVyA"
   },
   "outputs": [],
   "source": [
    "mdn = MDN(neurons=neurons, components=components, timesteps=7, features=1)\n",
    "mdn.compile(loss=gnll_loss, optimizer=opt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-ITpVxrPa0B0",
    "outputId": "9e399af6-d2a0-43c3-aa8a-c35c636acaae"
   },
   "outputs": [],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0PNeTjNJajjc"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6_ag_rdoEVvf",
    "outputId": "de0eb310-eb7f-43f0-fc7c-a64961940a45"
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "#mdn.fit(x=x_train, y=y_train, epochs=1000, validation_data=(x_val, y_val), callbacks=[tensorboard], batch_size=128, verbose=0)\n",
    "mdn.fit(x=X_train, y= y_train, epochs=2, validation_data=(X_test, y_test), batch_size=32, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oo-zZueKEVsx"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vi92K_HREVqO"
   },
   "outputs": [],
   "source": [
    "y_pred = mdn.predict(X_test, verbose=0)\n",
    "alpha_pred, mu_pred, sigma_pred = slice_parameter_vectors(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "iDMSkWM4YjBN",
    "outputId": "48076f5f-a8fd-4552-be84-80393e41a337"
   },
   "outputs": [],
   "source": [
    "print(alpha_pred)\n",
    "print(mu_pred)\n",
    "print(sigma_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fydYDnKZyhOp",
    "outputId": "9e97fa98-962a-4e16-9d44-3f8ac4be3cef"
   },
   "outputs": [],
   "source": [
    "print(alpha_pred.shape)\n",
    "print(mu_pred.shape)\n",
    "print(sigma_pred.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "V6JctC9aYpwE",
    "outputId": "6c510ae9-06de-4287-9bcc-fcacb0f9b985"
   },
   "outputs": [],
   "source": [
    "y_pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "O4hIm12DybD6",
    "outputId": "00808ccb-141a-4df3-e2ba-cc8e1cecd028"
   },
   "outputs": [],
   "source": [
    "mu_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XgoECleQaZZ6",
    "outputId": "e0955924-7226-4d49-8efc-13d0366b75dd"
   },
   "outputs": [],
   "source": [
    "y_pred[0][1]+y_pred[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "oSFO8EC5Ylwm",
    "outputId": "765d36e0-ad8c-4b28-814c-e70ef300ec0b"
   },
   "outputs": [],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zcn6hT9Wbg9r",
    "outputId": "740149a0-3045-4121-f7de-42efefe26ecc"
   },
   "outputs": [],
   "source": [
    "history = mdn.fit(X_train, y_train, epochs=2, validation_data=(X_test, y_test), batch_size=32, verbose=1)\n",
    "nll = history.history['loss'][-1]  # Access last epoch's NLL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "sIcmmMeZbwU6",
    "outputId": "025d06d7-8af1-4356-d501-3f547a009aff"
   },
   "outputs": [],
   "source": [
    "nll"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "7F5SHMEBt2Pu",
    "outputId": "c66a3433-754e-4f07-d513-054ed570ce5e"
   },
   "outputs": [],
   "source": [
    "\n",
    "def evaluate_and_visualize(mdn, X_test, y_test, num_samples=1000):\n",
    "    # Make predictions\n",
    "    y_pred = mdn.predict(X_test)\n",
    "    alpha_pred, mu_pred, sigma_pred = slice_parameter_vectors(y_pred)\n",
    "\n",
    "    # Sample and plot distributions for a few examples\n",
    "    for i in range(3):  # Plot for 3 test samples\n",
    "        # Sample from predicted mixture\n",
    "        samples = tf.random.normal(shape=(num_samples, n_components), mean=mu_pred[i], stddev=sigma_pred[i])\n",
    "\n",
    "        # Plot samples and predicted distributions\n",
    "        plt.hist(samples.numpy().flatten(), bins=50, density=True, label=\"Sampled Points\")\n",
    "        x = np.linspace(mu_pred[i] - 3 * sigma_pred[i], mu_pred[i] + 3 * sigma_pred[i], 100)  # Adjust range for visualization\n",
    "\n",
    "        # Assuming each component is Gaussian, plot individual Gaussian distributions\n",
    "        for k in range(n_components):\n",
    "            component_pdf = tfd.Normal(loc=mu_pred[i][k], scale=sigma_pred[i][k]).prob(x)\n",
    "            plt.plot(x, component_pdf, label=f\"Component {k+1}\")\n",
    "\n",
    "        plt.title(f\"Predicted Mixture Distribution (Sample {i+1})\")\n",
    "        plt.xlabel(\"Value\")\n",
    "        plt.ylabel(\"Density\")\n",
    "        plt.legend()\n",
    "        plt.show()\n",
    "\n",
    "evaluate_and_visualize(mdn, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "N8l3us2Qxr7Z"
   },
   "outputs": [],
   "source": [
    "def plot_prediction_intervals_mdn(mu_pred, sigma_pred, ts_Y_train, ts_Y_test):\n",
    "  \"\"\"\n",
    "  This function plots the predictions from an MDN model, including:\n",
    "  - Training data (blue circles)\n",
    "  - Testing data (gray circles)\n",
    "  - Point forecasts (one for each component, black and orange lines)\n",
    "  - Confidence intervals (one for each component, shaded areas)\n",
    "\n",
    "  Args:\n",
    "      mu_pred: NumPy array of predicted means (num_samples, n_components, forecast_h).\n",
    "      sigma_pred: NumPy array of predicted standard deviations (num_samples, n_components, forecast_h).\n",
    "      ts_Y_train: Time series training data.\n",
    "      ts_Y_test: Time series testing data.\n",
    "  \"\"\"\n",
    "\n",
    "  forecast_h = len(mu_pred[:, 0])\n",
    "  train_window = len(ts_Y_train)\n",
    "  x_length = forecast_h + train_window\n",
    "  aa = [x for x in range(x_length)]\n",
    "\n",
    "  plt.figure(figsize=(20, 8))\n",
    "\n",
    "  # Plot training and testing data\n",
    "  plt.plot(aa[:train_window], ts_Y_train, marker='o', label=\"Train\", color='blue')\n",
    "  plt.plot(aa[train_window:], ts_Y_test, marker='o', label=\"Test\", alpha=0.3, color='gray')\n",
    "\n",
    "  # Plot point forecasts (one for each component)\n",
    "  plt.plot(aa[train_window:], mu_pred[:, 0].reshape(-1), label=\"Forecast (Component 1)\", color='black', linewidth=2)\n",
    "  plt.plot(aa[train_window:], mu_pred[:, 1].reshape(-1), label=\"Forecast (Component 2)\", color='orange', linewidth=2)\n",
    "\n",
    "  # Plot confidence intervals (one for each component)\n",
    "  mean_1, std_1 = mu_pred[:, 0].reshape(-1), np.sqrt(sigma_pred[:, 0])**2\n",
    "  plt.errorbar(aa[train_window:], mean_1, yerr=std_1, color='red', fmt='o', label=\"Confidence Interval (Component 1)\")\n",
    "  plt.fill_between(aa[train_window:], mean_1 - std_1, mean_1 + std_1, color='b', alpha=0.2)\n",
    "\n",
    "  mean_2, std_2 = mu_pred[:, 1].reshape(-1), np.sqrt(sigma_pred[:, 1])**2\n",
    "  plt.errorbar(aa[train_window:], mean_2, yerr=std_2, color='red', fmt='o', label=\"Confidence Interval (Component 2)\")\n",
    "  plt.fill_between(aa[train_window:], mean_2 - std_2, mean_2 + std_2, color='orange', alpha=0.2)\n",
    "\n",
    "  # Adjust x-axis limits (optional)\n",
    "  # plt.xlim(0, x_length)  # Example: Set limits to cover entire data and forecast\n",
    "\n",
    "  # Customize plot further (e.g., titles, labels, legend)\n",
    "  plt.title('MDN Model Predictions')\n",
    "  plt.xlabel('Time Step')\n",
    "  plt.ylabel('Value')\n",
    "  plt.legend()\n",
    "  plt.tight_layout()\n",
    "  plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 283
    },
    "id": "M7jEa-rJxvWl",
    "outputId": "12ec2cbf-9d5d-4608-c826-a6d03e2379a3"
   },
   "outputs": [],
   "source": [
    "plot_prediction_intervals_mdn(mu_pred, sigma_pred, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jLCHJ8rNyOZ5",
    "outputId": "4ad694cc-f90a-4400-d3a9-f84a5b9d1cdb"
   },
   "outputs": [],
   "source": [
    "mu_pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 141
    },
    "id": "vWEIqwIr2FnE",
    "outputId": "646e18b2-7918-4f14-cfc9-bc950bfa61db"
   },
   "outputs": [],
   "source": [
    " aa.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dgXsU09x0Zss"
   },
   "outputs": [],
   "source": [
    "\n",
    "  forecast_h = len(mu_pred[:, 0])\n",
    "  train_window = len(y_train)\n",
    "  x_length = forecast_h + train_window\n",
    "  aa = [x for x in range(x_length)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 917
    },
    "id": "dVL9cI4Xw70Q",
    "outputId": "5e8ccad4-6bdc-4f20-ca9d-23608477b319"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "def plot_prediction_intervals_mdn(mu_pred, sigma_pred, ts_Y_train, ts_Y_test):\n",
    "  \"\"\"\n",
    "  This function plots the predictions from an MDN model, including:\n",
    "  - Training data\n",
    "  - Testing data\n",
    "  - Point forecasts (one for each component)\n",
    "  - Confidence intervals (one for each component)\n",
    "\n",
    "  Args:\n",
    "      mu_pred: NumPy array of predicted means (num_samples, n_components, forecast_h).\n",
    "      sigma_pred: NumPy array of predicted standard deviations (num_samples, n_components, forecast_h).\n",
    "      ts_Y_train: Time series training data.\n",
    "      ts_Y_test: Time series testing data.\n",
    "  \"\"\"\n",
    "\n",
    "  forecast_h = len(mu_pred[:, 0])\n",
    "  train_window = len(ts_Y_train)\n",
    "  x_length = forecast_h + train_window\n",
    "  aa = [x for x in range(x_length)]\n",
    "\n",
    "  # plt.figure(figsize=(12, 8))\n",
    "\n",
    "  # Plot training and testing data\n",
    "  # plt.plot(aa[:train_window], ts_Y_train, marker='o', label=\"Train\", color='blue')\n",
    "  plt.plot(aa[train_window:], ts_Y_test,  label=\"Test\", alpha=0.8, color='black')\n",
    "\n",
    "  # Plot point forecasts (one for each component)\n",
    "  #plt.plot(aa[train_window:], mu_pred[:, 0].reshape(-1), label=\"Forecast (Component 1)\", color='yellow')\n",
    "  plt.plot(aa[train_window:], mu_pred[:, 1].reshape(-1), label=\"Forecast (Component 2)\", color='orange')\n",
    "\n",
    "  # Plot confidence intervals (one for each component)\n",
    "  mean_1, std_1 = mu_pred[:, 0].reshape(-1), np.sqrt(sigma_pred[:, 0])**2\n",
    "  #plt.errorbar(aa[train_window:], mean_1, yerr=std_1, color='yellow',label=\"Confidence Interval (Component 1)\")\n",
    "  #plt.fill_between(aa[train_window:], mean_1 - std_1, mean_1 + std_1, color='b', alpha=0.8)\n",
    "\n",
    "  # mean_2, std_2 = mu_pred[:, 1].reshape(-1), np.sqrt(sigma_pred[:, 1])**2\n",
    "  # plt.errorbar(aa[train_window:], mean_2, yerr=std_2, color='red', fmt='o', label=\"Confidence Interval (Component 2)\")\n",
    "  # plt.fill_between(aa[train_window:], mean_2 - std_2, mean_2 + std_2, color='orange', alpha=0.2)\n",
    "\n",
    "  # Adjust x-axis limits (optional)\n",
    "  # plt.xlim(0, x_length)  # Example: Set limits to cover entire data and forecast\n",
    "\n",
    "  # Customize plot further (e.g., titles, labels, legend)\n",
    "  plt.title('MDN Model Predictions')\n",
    "  plt.xlabel('Time Step')\n",
    "  plt.ylabel('Value')\n",
    "  plt.legend()\n",
    "  plt.tight_layout()\n",
    "  plt.show()\n",
    "\n",
    "\n",
    "plot_prediction_intervals_mdn(mu_pred, sigma_pred, y_train, y_test)\n",
    "plt.plot(y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TshZ2YGUANxO"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GYgtkXIO_wQ9"
   },
   "outputs": [],
   "source": [
    "first_mean_array = mu_pred[:, 1]  # Assuming mu_pred has dimensions (num_samples, n_components, forecast_h)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bF6JzrMD_45n",
    "outputId": "0b8d3bfd-d2d7-4585-fe04-6822bad9fb9c"
   },
   "outputs": [],
   "source": [
    "first_mean_array.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 447
    },
    "id": "No_hiE7qASuo",
    "outputId": "8db4e7b6-4c5b-4517-86ee-d3a5a126437d"
   },
   "outputs": [],
   "source": [
    "\n",
    "plt.plot(first_mean_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PPqNtayB_Gaj",
    "outputId": "8f70275f-8eb6-4111-cd07-69b0f5203b92"
   },
   "outputs": [],
   "source": [
    "y_test.shape\n",
    "mu_pred[:][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0XYh-qJQ_Dl_",
    "outputId": "03184783-404e-48d0-9d71-2b2c01ccc8f2"
   },
   "outputs": [],
   "source": [
    "\n",
    "def calculate_mape(y_true, y_pred):\n",
    "\n",
    "    y_true = np.array(y_true)\n",
    "    y_pred = np.array(y_pred)\n",
    "\n",
    "    ape = np.abs((y_true - y_pred) / y_true)\n",
    "\n",
    "    ape[np.isnan(ape)] = 0\n",
    "\n",
    "    mape = np.mean(ape) * 100\n",
    "\n",
    "    return mape\n",
    "\n",
    "mape = calculate_mape(y_test, first_mean_array)\n",
    "print(\"MAPE:\", mape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "AdjRUuuVAx5-",
    "outputId": "058d1b55-cb54-4fd4-9e14-4c93954876e4"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "mse = mean_squared_error(y_test, first_mean_array)\n",
    "r2 = r2_score(y_test, first_mean_array)\n",
    "\n",
    "print(\"Mean Squared Error:\", mse)\n",
    "print(\"R-squared:\", r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5J8rAcKCHmEK"
   },
   "outputs": [],
   "source": [
    "    def plot_prediction_intervals_mdn(mu_pred, sigma_pred, ts_Y_train, ts_Y_test):\n",
    "    forecast_h = len(mu_pred[:,0])\n",
    "    train_window = len(ts_Y_train)\n",
    "    x_length = forecast_h+train_window\n",
    "    aa=[x for x in range(x_length)]\n",
    "    plt.figure(figsize=(20,8))\n",
    "    plt.plot(aa[:train_window], ts_Y_train, marker='.', label=\"train\")\n",
    "    plt.plot(aa[train_window:], ts_Y_test, marker='.', label=\"test\",  alpha=0.3)\n",
    "    plt.plot(aa[train_window:], mu_pred[:,0].reshape(-1), label=\"forecast\", color='black', linewidth=2)\n",
    "\n",
    "    mean_1, std_1 = mu_pred[:,0].reshape(-1), np.sqrt(sigma_pred[:,0])**2\n",
    "    plt.errorbar(aa[train_window:], mean_1, yerr=std_1 , color='red', fmt='.');\n",
    "    plt.fill_between(aa[train_window:], mean_1 - std_1, mean_1 + std_1, color='b', alpha=0.2)\n",
    "\n",
    "    mean_2, std_2 = mu_pred[:,1].reshape(-1), np.sqrt(sigma_pred[:,1])**2\n",
    "    plt.plot(aa[train_window:], mean_2, label=\"forecast\", color='black', linewidth=2)\n",
    "    plt.errorbar(aa[train_window:], mean_2, yerr=std_2, color='red', fmt='.');\n",
    "    plt.fill_between(aa[train_window:], mean_2 - std_2, mean_2 + std_2, color='b', alpha=0.2)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.subplots_adjust(left=0.07)\n",
    "    plt.xlabel('time step', size=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 447
    },
    "id": "yPsygkSY37iH",
    "outputId": "be7f49c0-e7ca-4feb-c55f-202928c2fa4b"
   },
   "outputs": [],
   "source": [
    "plt.plot(load_train)\n",
    "plt.figure(figsize=(12, 8))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oCNh5PT04Yvi"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 430
    },
    "id": "mwVwa6jB4TNN",
    "outputId": "617ff286-e6ff-4eeb-8aa9-bf869f9b24f3"
   },
   "outputs": [],
   "source": [
    "plt.plot(load_test)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 305
    },
    "id": "WrfWqftrHmBb",
    "outputId": "2d5528a4-c61b-4cda-9fb3-77870a221fb0"
   },
   "outputs": [],
   "source": [
    "plot_prediction_intervals_mdn(mu_pred, sigma_pred, y_train, y_test)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 303
    },
    "id": "CAweZKyVHl_A",
    "outputId": "614a00ce-0879-4c6f-a68f-99e954f27308"
   },
   "outputs": [],
   "source": [
    "plot_prediction_intervals_mdn(mu_pred, sigma_pred, y_train, y_test)\n",
    "plt.xlim(350,480)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 717
    },
    "id": "RF9fhlrNHl7-",
    "outputId": "e3fa0fa1-d8a7-4660-dc88-559efe1ba691"
   },
   "outputs": [],
   "source": [
    "def plot_forecast_dist(ax, index, col_index):\n",
    "    mdn_alpha, mdn_mu, mdn_sigma = slice_parameter_vectors(mdn.predict(X_test[index].reshape(1,X_test[index].shape[0], -1)))\n",
    "\n",
    "    gm = tfd.MixtureSameFamily(\n",
    "            mixture_distribution=tfd.Categorical(probs=mdn_alpha),\n",
    "            components_distribution=tfd.Normal(\n",
    "                loc=mdn_mu,\n",
    "                scale=mdn_sigma))\n",
    "    pyx = gm.prob(x)\n",
    "    la = \"Date index {:3d}\".format(index + len(y_train))\n",
    "    ax.plot(x,pyx, alpha=1, color=sns.color_palette(\"tab10\")[col_index], linewidth=2, label=la)\n",
    "\n",
    "x = np.linspace(-20,40,int(1e3))\n",
    "\n",
    "fig = plt.figure(figsize=(8,4), dpi=100)\n",
    "ax = plt.gca()\n",
    "\n",
    "dates_index = [10, 80]\n",
    "icol = 0\n",
    "for date_idx in dates_index:\n",
    "    plot_forecast_dist(ax, date_idx, icol)\n",
    "    icol+=1\n",
    "\n",
    "ax.set_xlabel('y')\n",
    "ax.set_ylabel(\"p(y|date)\")\n",
    "ax.legend(loc=0, borderaxespad=0.1, framealpha=1.0, fancybox=True, ncol=1, shadow=True, frameon=False, fontsize=8)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FH9T6yCWER05"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "n6BJCPpqmgd4"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "eJeI11Jxmgay"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "iuv7PTFjmgX-"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_LKD1DROmgVa"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EMCMlFtFJKzu"
   },
   "outputs": [],
   "source": [
    "# -----  quantiles to be predicted\n",
    "QUANTILES = [0.1, 0.3, 0.5, 0.7, 0.9] # N quantiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KUf3QiVAJKwy"
   },
   "outputs": [],
   "source": [
    "def tilted_loss(q, y, f):\n",
    "    #e = (y - f) sometimes the error is computed in this form. Quantiles are inverted\n",
    "    e = (f - y)\n",
    "    return keras.backend.mean(keras.backend.maximum(q * e, (q - 1) * e), axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IbOV-tRZJKt9"
   },
   "outputs": [],
   "source": [
    "def lstm_dqr_model(X, ts_Y_train, n_steps, n_features, q):\n",
    "    # define model\n",
    "    model = tf.keras.Sequential()\n",
    "    model.add(layers.LSTM(50, activation='relu', input_shape=(timesteps, features)))\n",
    "    model.add(layers.Dense(1))\n",
    "    model.compile(optimizer='adagrad', loss=lambda y, f: tilted_loss(q, y, f))\n",
    "    # fit model\n",
    "    model.fit(X, ts_Y_train, epochs=4, verbose=2)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pR7Ae-nxIl5_"
   },
   "outputs": [],
   "source": [
    "num_layers=2\n",
    "def lstm_dqr_model(X, ts_Y_train, n_steps, n_features, q):\n",
    "    # define model\n",
    "    model = tf.keras.Sequential()\n",
    "    for i in range(num_layers):\n",
    "        if i == 0:\n",
    "            model.add(layers.LSTM(50,activation='relu', input_shape=(timesteps, features), return_sequences=True))\n",
    "        else:\n",
    "            model.add(layers.LSTM(32,activation='relu', return_sequences=True))\n",
    "     # Access only the last time step output\n",
    "    model.add(layers.Lambda(lambda x: x[:, -1, :]))  # Extract the last time step\n",
    "\n",
    "    model.add(layers.Dense(1))\n",
    "    model.compile(optimizer='adagrad', loss=lambda y, f: tilted_loss(q, y, f))\n",
    "    # fit model\n",
    "    model.fit(X, ts_Y_train, epochs=4, verbose=2)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "E64iDUwnJo9k"
   },
   "outputs": [],
   "source": [
    "timesteps=7\n",
    "features=1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4d6ilSWPJKrS",
    "outputId": "f79dad26-7fca-40e0-c3a2-5f1b72135e6b"
   },
   "outputs": [],
   "source": [
    "q_models = []\n",
    "\n",
    "for i in range(0,len(QUANTILES)):\n",
    "    q_models.append(lstm_dqr_model(X_train, y_train, timesteps, features, QUANTILES[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hBcb4qX6ME0n",
    "outputId": "a379a771-8a26-4c7c-8828-811067f086d8"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_fSRJtfAJKkE",
    "outputId": "c2c31bb0-4f95-4afe-8f04-d5da544c6a5b"
   },
   "outputs": [],
   "source": [
    "q_yhat = []\n",
    "\n",
    "# predict each quantile of QUANTILES list\n",
    "for i in range(0,len(QUANTILES)):\n",
    "    q_yhat.append(q_models[i].predict(X_test, verbose=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "m-m2xcgeuRlm",
    "outputId": "38bde45a-4802-462f-c7fc-d23bcf7d6aa4"
   },
   "outputs": [],
   "source": [
    "q_yhat[1][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "x7t3pVFFtCi5",
    "outputId": "cd2c0db7-2bb8-4de4-bc91-8b137c795869"
   },
   "outputs": [],
   "source": [
    "for i in range(5):\n",
    " print( q_yhat[i].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 380
    },
    "id": "kfIsvBPWgtlq",
    "outputId": "0e51b61c-1f07-415b-b225-a989be41f508"
   },
   "outputs": [],
   "source": [
    "def plot_ts_forecast(y_true, q_yhat, quantiles=False, title=\"Forecast with Quantiles\", zoom_range=None):\n",
    "  if zoom_range is not None:  # Create fig and ax only for zoom plot\n",
    "    fig, ax = plt.subplots(figsize=(12, 6))\n",
    "  else:\n",
    "    plt.figure(figsize=(12, 6))  # Create figure for non-zoom plot\n",
    "    ax = plt.gca()  # Get current axis\n",
    "  if zoom_range is not None:\n",
    "    plt.xlim(zoom_range[0], zoom_range[1])\n",
    "  plt.plot(y_true, label=\"True Values\")\n",
    "  if quantiles:\n",
    "    # ... (assuming q_yhat is a list of predicted quantiles)\n",
    "    for i, quantile in enumerate(QUANTILES):\n",
    "      plt.plot(q_yhat[i].squeeze(), label=f\"{quantile * 100}% Quantile\")\n",
    "  else:\n",
    "    plt.plot(y_pred.squeeze(), label=\"Predicted Value\")\n",
    "  plt.xlabel(\"Time Step\")\n",
    "  plt.ylabel(\"Value\")\n",
    "  plt.title(title)\n",
    "  plt.legend()\n",
    "  plt.grid(True)\n",
    "\n",
    "  # Interactive zooming with slider (optional)\n",
    "  if zoom_range is not None:\n",
    "    from matplotlib.widgets import Slider\n",
    "    vmin, vmax = zoom_range\n",
    "    slider_ax = fig.add_axes([0.2, 0.1, 0.65, 0.03])\n",
    "    slider = Slider(ax=slider_ax, label='X-axis Zoom', valmin=vmin, valmax=vmax, valinit=vmin)\n",
    "\n",
    "    def update(val):\n",
    "      ax.set_xlim([val, val + (vmax - vmin)])\n",
    "      fig.canvas.draw_idle()\n",
    "\n",
    "    slider.on_changed(update)\n",
    "\n",
    "  plt.show()\n",
    "\n",
    "# Example usage with error checking and zoom range adjustment\n",
    "def check_data_compatibility(y_true, q_yhat):\n",
    "  if len(y_true) != len(q_yhat[0]):\n",
    "    raise ValueError(\"Length mismatch between y_true and predicted quantiles!\")\n",
    "  for pred in q_yhat:\n",
    "    if len(pred) != len(y_true):\n",
    "      raise ValueError(\"Length mismatch within predicted quantiles!\")\n",
    "\n",
    "\n",
    "try:\n",
    "  check_data_compatibility(y_test, q_yhat)\n",
    "\n",
    "  zoom_range = (350, 480)  # Adjust zoom range as needed\n",
    "  plot_ts_forecast(y_test, q_yhat, quantiles=True, title=\"Forecast with Quantiles\", zoom_range=zoom_range)\n",
    "except ValueError as e:\n",
    "  print(f\"Error: {e}\")\n",
    "  print(\"Please check your data and code for compatibility issues.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "44hRrbp78ED5",
    "outputId": "86518c70-e8f9-437c-feda-e2166c4e9534"
   },
   "outputs": [],
   "source": [
    "\n",
    "# Iterate through each quantile\n",
    "for i, quantile in enumerate(QUANTILES):\n",
    "\n",
    "    # Access the predicted values for the current quantile\n",
    "    predicted_quantile = q_yhat[i][ start_index:end_index]\n",
    "\n",
    "    # Create the plot with appropriate labels and title\n",
    "    plt.plot(predicted_quantile, label=f\"Predicted ({quantile})\")\n",
    "    plt.plot(y_test[start_index:end_index], color='red', label=\"Actual\")\n",
    "    plt.xlabel('Time')\n",
    "    plt.ylabel('Load')\n",
    "    plt.title(f'QLSTM Predictions for Load for 2 days (Quantile {quantile})')\n",
    "    plt.legend()\n",
    "    plt.show()  # Show each plot individually"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 584
    },
    "id": "XCkqDR_wAD6d",
    "outputId": "b96b9f01-7078-4716-a91f-12d53f3cf1a5"
   },
   "outputs": [],
   "source": [
    "# Define line styles and colors (optional)\n",
    "line_styles = ['-', '--', ':', '-.', ':']\n",
    "colors = ['b', 'g', 'r', 'c', 'm']  # Adjust colors as needed\n",
    "\n",
    "# Create the main plot\n",
    "plt.figure(figsize=(12, 6))  # Adjust figure size as needed\n",
    "\n",
    "# Plot actual values\n",
    "plt.plot(y_test[start_index:end_index], color='red', label=\"Actual\", linewidth=2)\n",
    "\n",
    "# Plot for each quantile\n",
    "for i, (quantile, line_style, color) in enumerate(zip(QUANTILES, line_styles, colors)):\n",
    "    predicted_quantile = q_yhat[i] [start_index:end_index]\n",
    "    plt.plot(predicted_quantile, label=f\"Predicted ({quantile})\", linestyle=line_style, color=color)\n",
    "\n",
    "# Set labels and title\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('Load')\n",
    "plt.title('QLSTM Predictions for Load for 2 days (All Quantiles)')\n",
    "plt.legend()\n",
    "plt.grid(True)  # Add grid for better readability (optional)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 385
    },
    "id": "O2lVkvseiqhl",
    "outputId": "91ed5678-3450-4abc-92cc-e64586dac3d5"
   },
   "outputs": [],
   "source": [
    "# Function to plot time series forecast with predicted quantiles\n",
    "def plot_ts_forecast(y_true, q_yhat, quantiles=False, title=\"Forecast with Quantiles\", zoom_range=None):\n",
    "  if zoom_range is not None:\n",
    "    fig, ax = plt.subplots(figsize=(12, 6))  # Create figure and axis for zoom plot\n",
    "  else:\n",
    "    plt.figure(figsize=(12, 6))  # Create figure for non-zoom plot\n",
    "    ax = plt.gca()  # Get current axis\n",
    "\n",
    "  plt.plot(y_true, label=\"True Values\")\n",
    "  if quantiles:\n",
    "    # Assuming q_yhat is a list of predicted quantiles (one for each model)\n",
    "    for i, quantile in enumerate(QUANTILES):\n",
    "      plt.plot(q_yhat[i].squeeze(), label=f\"{quantile * 100}% Quantile\")\n",
    "  else:\n",
    "    plt.plot(y_pred.squeeze(), label=\"Predicted Value\")\n",
    "  plt.xlabel(\"Time Step\")\n",
    "  plt.ylabel(\"Value\")\n",
    "  plt.title(title)\n",
    "  plt.legend()\n",
    "  plt.grid(True)\n",
    "# Interactive zooming with slider (optional)\n",
    "  if zoom_range is not None:\n",
    "    from matplotlib.widgets import Slider\n",
    "\n",
    "    # Ensure zoom_range reflects actual data range (adjust as needed)\n",
    "    data_min = np.min(y_true)  # Assuming y_true holds your time series data\n",
    "    data_max = np.max(y_true)\n",
    "    zoom_range = (data_min - 5, data_max + 5)  # Allow some buffer around data range\n",
    "\n",
    "  # Interactive zooming with slider (optional)\n",
    "  if zoom_range is not None:\n",
    "    from matplotlib.widgets import Slider\n",
    "\n",
    "    # Define slider limits based on zoom_range\n",
    "    vmin, vmax = zoom_range\n",
    "\n",
    "    # Create slider axes (location and size)\n",
    "    slider_ax = fig.add_axes([0.2, 0.1, 0.65, 0.03])\n",
    "\n",
    "    # Create the slider object\n",
    "    slider = Slider(ax=slider_ax, label='X-axis Zoom', valmin=vmin, valmax=vmax, valinit=vmin)\n",
    "\n",
    "    def update(val):\n",
    "      # Update x-axis limits based on slider value\n",
    "      ax.set_xlim([val, val + (vmax - vmin)])\n",
    "      # Update the plot\n",
    "      fig.canvas.draw_idle()\n",
    "\n",
    "    # Connect slider and update function\n",
    "    slider.on_changed(update)\n",
    "\n",
    "  plt.show()\n",
    "\n",
    "# Example usage with error checking and zoom range adjustment\n",
    "def check_data_compatibility(y_true, q_yhat):\n",
    "  if len(y_true) != len(q_yhat[0]):\n",
    "    raise ValueError(\"Length mismatch between y_true and predicted quantiles!\")\n",
    "  for pred in q_yhat:\n",
    "    if len(pred) != len(y_true):\n",
    "      raise ValueError(\"Length mismatch within predicted quantiles!\")\n",
    "\n",
    "\n",
    "try:\n",
    "  check_data_compatibility(y_test, q_yhat)  # Check data compatibility before plotting\n",
    "\n",
    "  # zoom_range = (5, 50)  # Adjust zoom range as needed\n",
    "  plot_ts_forecast(y_test, q_yhat, quantiles=True, title=\"Forecast with Quantiles\", zoom_range=zoom_range)\n",
    "except ValueError as e:\n",
    "  print(f\"Error: {e}\")\n",
    "  print(\"Please check your data and code for compatibility issues.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qmT2FbHdngCr",
    "outputId": "8ec11054-3547-409d-b1bb-f2eccebc1a45"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tensorflow.keras import backend as K\n",
    "\n",
    "# Define custom quantile loss function (Pinball Loss)\n",
    "def pinball_loss(q, y, f):\n",
    "  e = (f - y)  # Error calculation\n",
    "  return K.mean(K.maximum(q * e, (q - 1) * e), axis=-1)\n",
    "\n",
    "# ... (Rest of your code for training and prediction with QLSTM)\n",
    "\n",
    "# Function to calculate coverage for a specific quantile\n",
    "def calculate_coverage(y_true, q_yhat, quantile):\n",
    "  # Assuming q_yhat is a list of predicted quantiles for each target quantile\n",
    "  lower_bound = q_yhat[QUANTILES.index(quantile) - 1].squeeze()\n",
    "  upper_bound = q_yhat[QUANTILES.index(quantile)].squeeze()\n",
    "  in_range = np.logical_and(y_true >= lower_bound, y_true <= upper_bound)\n",
    "  return np.mean(in_range) * 100  # Coverage as percentage\n",
    "\n",
    "# Example usage after prediction\n",
    "coverage_01 = calculate_coverage(y_test, q_yhat, 0.1)\n",
    "coverage_05 = calculate_coverage(y_test, q_yhat, 0.5)\n",
    "coverage_09 = calculate_coverage(y_test, q_yhat, 0.9)\n",
    "\n",
    "print(\"Coverage (10th Quantile):\", coverage_01, \"%\")\n",
    "print(\"Coverage (Median Quantile):\", coverage_05, \"%\")\n",
    "print(\"Coverage (90th Quantile):\", coverage_09, \"%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FYwT9wzCnf61"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NwZpUUPFnf4F"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JIHGH6OKnf1U"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DKUWwIj4nfuz"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6h5rD8Fvnfpa"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qSp9LupPnfmC"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QXh46wHQnfjR"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "aT6eedIBnfga"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "33dqlZmmnfde"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tLiFrzqGnfaj"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Nkh0uU3JXBEO"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "# Define custom loss function for probabilistic forecasting\n",
    "def quantile_loss(quantiles):\n",
    "    def loss(y_true, y_pred):\n",
    "        losses = []\n",
    "        for i, q in enumerate(quantiles):\n",
    "            error = y_true - y_pred[:, i]  # Extract predictions for the current quantile\n",
    "            loss_q = keras.backend.mean(keras.backend.maximum(q * error, (q - 1) * error))\n",
    "            losses.append(loss_q)\n",
    "        return keras.backend.mean(losses)\n",
    "    return loss\n",
    "\n",
    "# Define LSTM-based probabilistic forecasting model\n",
    "def build_lstm_model(input_shape, num_units=32, num_layers=2, num_quantiles=3):\n",
    "    model = keras.Sequential()\n",
    "    for i in range(num_layers):\n",
    "        if i == 0:\n",
    "            model.add(layers.LSTM(num_units, input_shape=input_shape, return_sequences=True))\n",
    "        else:\n",
    "            model.add(layers.LSTM(num_units, return_sequences=True))\n",
    "    model.add(layers.Dense(num_quantiles, activation='linear'))\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 547
    },
    "id": "yyZ0Pcj9XBB7",
    "outputId": "d51ba261-9ff7-4c90-c073-068b7edb4161"
   },
   "outputs": [],
   "source": [
    "\n",
    "# Reshape input data\n",
    "X_train = X_train.reshape((X_train.shape[0], X_train.shape[1], 1))\n",
    "\n",
    "# Define model architecture\n",
    "input_shape = (X_train.shape[1], X_train.shape[2])\n",
    "model = build_lstm_model(input_shape)\n",
    "\n",
    "# Compile model\n",
    "quantiles = np.array([0.1, 0.5, 0.9])  # Define quantiles for probabilistic forecasting\n",
    "model.compile(optimizer='adam', loss=quantile_loss(quantiles))\n",
    "\n",
    "# Train model\n",
    "model.fit(X_train, y_train, epochs=2, batch_size=64, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wsM8DrhcXA1e"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8BQWMHGxXAyt"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cByc4ovVXAwo"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "J0LtIgjVXAt2"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "b0uhTh4hXApN"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZPNr-mRrXAmd"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "VGUip9TDHqEJ",
    "outputId": "56b3246f-a905-4d22-f23f-43bcba543b61"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "num_last_values = 960\n",
    "total_samples = len(X)\n",
    "\n",
    "test_indices = range(total_samples - num_last_values, total_samples)\n",
    "\n",
    "# Split the data into train and test sets using the defined test indices\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=len(test_indices), random_state=0, shuffle=False)\n",
    "\n",
    "print(\"X_train shape:\", X_train.shape)\n",
    "print(\"X_test shape:\", X_test.shape)\n",
    "print(\"y_train shape:\", y_train.shape)\n",
    "print(\"y_test shape:\", y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-S9PsXDideRo",
    "outputId": "bf1a5fb3-c263-47c4-f7f9-bd6e3d5ec6e4"
   },
   "outputs": [],
   "source": [
    "\n",
    "print(\"y_test:\", list(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "aZlqfKCyJ8RC",
    "outputId": "7779bf3c-5213-41e7-f6dc-a437992569c0"
   },
   "outputs": [],
   "source": [
    "m = len(time) - 960\n",
    "\n",
    "load_train = load[:m]\n",
    "load_test = load[m:]\n",
    "\n",
    "print(\"Load_train shape:\",load_train.shape)\n",
    "print(\"Load_test shape:\", load_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Wh-IMpoMJ8LF"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "um8BgYD7JgrU"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5aMtklDgKZag",
    "outputId": "ba453885-3d8b-411a-c732-0e3d9aca73f3"
   },
   "outputs": [],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "TXfW_GNDUvOj",
    "outputId": "725c0410-21f1-415e-da66-810aa6e28538"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import BatchNormalization, Dropout\n",
    "\n",
    "# Define the LSTM model with optimizations\n",
    "model = Sequential()\n",
    "model.add(LSTM(50, input_shape=(X_train.shape[1], 1), return_sequences=True))\n",
    "model.add(Dropout(0.4))\n",
    "\n",
    "model.add(LSTM((50), return_sequences=True))\n",
    "model.add(Dropout(0.4))\n",
    "\n",
    "model.add(LSTM((50), return_sequences=True))\n",
    "model.add(Dropout(0.4))\n",
    "model.add(LSTM(50))\n",
    "model.add(Dropout(0.4))\n",
    "model.add(Dense(1))\n",
    "\n",
    "# Compile the model with a lower learning rate and use early stopping\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=0.001)\n",
    "model.compile(loss='mse', optimizer='adam', metrics=['mae'])\n",
    "\n",
    "# # Implement early stopping\n",
    "# early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
    "\n",
    "# # Train the model with early stopping\n",
    "# model.fit(X_train, y_train, epochs=20, batch_size=32, validation_data=(X_test, y_test), callbacks=[early_stopping])\n",
    "# Train the model with early stopping\n",
    "model.fit(X_train, y_train, epochs=20, batch_size=32, validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6u2h8XrVJP5M",
    "outputId": "cd07d852-6834-4000-e715-2e59403016be"
   },
   "outputs": [],
   "source": [
    "  # Assuming your model is already trained and you have test data X_test\n",
    "\n",
    "# Make predictions on the test data\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# The predictions will be probabilities since you're using a sigmoid activation in the output layer.\n",
    "# If you want binary predictions, you can round the probabilities to 0 or 1.\n",
    "binary_predictions = (y_pred > 0.5).astype('int')\n",
    "\n",
    "# Optionally, you can evaluate the performance of your model on the test set\n",
    "loss, accuracy = model.evaluate(X_test, y_test)\n",
    "print(\"Test Loss:\", loss)\n",
    "print(\"Test Accuracy:\", accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IE9JUAX5JP3d",
    "outputId": "2d607704-4afb-4d4f-8376-228c75b58cd4"
   },
   "outputs": [],
   "source": [
    "y_pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ufmicujSJP0p"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "uVR96z_kJPyB",
    "outputId": "42e4c767-4e9b-46d4-c7e3-5a4bd127cb0e"
   },
   "outputs": [],
   "source": [
    "y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jDjdT5Z_JPu8"
   },
   "outputs": [],
   "source": [
    "y_pred=y_pred.reshape(-1,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vpErlc4kJPrL"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "895pHpbXJPpd"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zrtXhvJMJPmF"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OQ3w_6K6KBS_"
   },
   "outputs": [],
   "source": [
    "comparison = pd.DataFrame({'Actual': y_test, 'Predicted': y_pred})\n",
    "print(comparison)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8EkGUntWYF1Y"
   },
   "outputs": [],
   "source": [
    "df1 = pd.DataFrame(y_test)\n",
    "df2 = pd.DataFrame(y_pred)\n",
    "\n",
    "result_df = pd.concat([df1, df2], axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UAhpiYJmKBQj"
   },
   "outputs": [],
   "source": [
    "\n",
    "np.set_printoptions(precision=2)\n",
    "print(np.concatenate((y_pred.reshape(len(y_pred),1), y_test.reshape(len(y_test),1)),1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 472
    },
    "id": "_ukS79DhKBOO",
    "outputId": "cd6e1f79-7376-4767-b7ea-946b550e8bd0"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "# Plot original data and predictions\n",
    "# plt.plot(load, label='Original Load')\n",
    "plt.plot(y_pred, label=\"Predicted\" )\n",
    "plt.plot(y_test,color='red',label=\"Actual\")\n",
    "# plt.plot(np.arange(len(load), len(load)+n_steps), predictions, label='Predictions')\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('Load')\n",
    "plt.title('Linear Regression Model Predictions for Load')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 472
    },
    "id": "tizHhvCKiC1O",
    "outputId": "8b278917-a197-47a4-a450-21aab4591d41"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Define the start and end indices for the portion of data to plot\n",
    "start_index = 96*4\n",
    "end_index = 96*6\n",
    "\n",
    "\n",
    "plt.plot(y_pred[start_index:end_index], label=\"Predicted\")\n",
    "plt.plot(y_test[start_index:end_index], color='red', label=\"Actual\")\n",
    "\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('Load')\n",
    "plt.title('Linear Regression Model Predictions for Load for 2 days')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ra9vqdbpurec",
    "outputId": "b6a2531d-91c3-4310-ca27-bedd7e77c71d"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "print(\"Mean Squared Error:\", mse)\n",
    "print(\"R-squared:\", r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "K8aQQoDIWLeL"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "print(\"Mean Squared Error:\", mse)\n",
    "print(\"R-squared:\", r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uvmmnZWIbVE1"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "print(\"Mean Squared Error:\", mse)\n",
    "print(\"R-squared:\", r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wGaNtIJcWPTq",
    "outputId": "9655b3f8-9856-44c0-b7ce-a5fbc07268c3"
   },
   "outputs": [],
   "source": [
    "def mean_absolute_percentage_error(y_test, y_pred):\n",
    "    return np.mean(np.abs((y_pred - y_test) / y_test)) * 100\n",
    "\n",
    "\n",
    "mape = mean_absolute_percentage_error(y_test, y_pred)\n",
    "print(\"Mean Absolute Percentage Error (MAPE):\", mape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gc4ibqNqs8SP"
   },
   "outputs": [],
   "source": [
    "def mean_absolute_percentage_error(y_test, y_pred):\n",
    "    return np.mean(np.abs((y_pred - y_test) / y_test)) * 100\n",
    "\n",
    "\n",
    "mape = mean_absolute_percentage_error(y_test, y_pred)\n",
    "print(\"Mean Absolute Percentage Error (MAPE):\", mape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PydrhBoiIVlq"
   },
   "outputs": [],
   "source": [
    "# Get the slope (coefficients) and intercept of the linear regression model\n",
    "coefficients = model.coef_\n",
    "intercept = model.intercept_\n",
    "\n",
    "print(\"Coefficients:\", coefficients)\n",
    "print(\"Intercept:\", intercept)\n",
    "\n",
    "# Form the equation of the line\n",
    "equation_parts = [f\"{coefficients[i]:.2f}x{i+1}\" for i in range(len(coefficients))]\n",
    "equation = \" + \".join(equation_parts) + f\" + {intercept:.2f}\"\n",
    "print(\"Equation of the line:\", equation)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "eVkyINAqM7VE"
   },
   "outputs": [],
   "source": [
    "coefficients = model.coef_\n",
    "intercept =model.intercept_\n",
    "\n",
    "# Display coefficients\n",
    "for i in range(len(coefficients)):\n",
    "    print(f\"Coefficient for x{i+1}: {coefficients[i]}\")\n",
    "\n",
    "print(\"Intercept:\", intercept)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dETp8yK4aFwG"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Oc3IzO9QaFyt"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "# Plot original data and predictions\n",
    "# plt.plot(load, label='Original Load')\n",
    "plt.plot(z_remaining, label=\"Scheduled\" )\n",
    "plt.plot(y_test,color='red',label=\"Actual\")\n",
    "# plt.plot(np.arange(len(load), len(load)+n_steps), predictions, label='Predictions')\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('Load')\n",
    "plt.title('Scheduled vs Load')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gIS4WyaIin1J"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "start_index = 96*4\n",
    "end_index = 96*6\n",
    "\n",
    "# Plot selected portion of original data and predictions\n",
    "plt.plot(z_remaining[start_index:end_index], label=\"Scheduled\")\n",
    "plt.plot(y_test[start_index:end_index], color='red', label=\"Actual\")\n",
    "\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('Load')\n",
    "plt.title('Scheduled vs Load for 2 days')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LwjBnKp4aF1Q"
   },
   "outputs": [],
   "source": [
    "def mean_absolute_percentage_error(y_test, z_remaining ):\n",
    "    return np.mean(np.abs((z_remaining - y_test) / y_test)) * 100\n",
    "\n",
    "# Assuming y_true and y_pred are the true and predicted values, respectively\n",
    "mape = mean_absolute_percentage_error(y_test, z_remaining )\n",
    "print(\"Mean Absolute Percentage Error (MAPE) for load vs scheduled:\", mape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6OCjESVIf6Ph"
   },
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "mse = mean_squared_error(y_test, z_remaining)\n",
    "r2 = r2_score(y_test,z_remaining)\n",
    "\n",
    "print(\"Mean Squared Error:\", mse)\n",
    "print(\"R-squared:\", r2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "U2OXitSnX0Db"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cFLuYOHMX0Ai"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0MWZYAjYXz8k"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "llF1lpAhf6Mn"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gQ2ppLvYM7S0"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "\n",
    "ann = tf.keras.models.Sequential()\n",
    "ann.add(tf.keras.layers.Dense(units=18, activation='relu'))\n",
    "ann.add(tf.keras.layers.Dense(units=18, activation='relu'))\n",
    "ann.add(tf.keras.layers.Dense(units=18, activation='relu'))\n",
    "ann.add(tf.keras.layers.Dense(units=1))\n",
    "ann.compile(optimizer = 'RMSProp', loss = 'mean_squared_error',metrics=['accuracy'])\n",
    "ann.fit(X_train, y_train, batch_size = 32, epochs = 10)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xtWeg-4FKJkn"
   },
   "outputs": [],
   "source": [
    "loss, accuracy = ann.evaluate(X, y)\n",
    "print(\"Loss:\", loss)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cxyMCPylI7pz"
   },
   "outputs": [],
   "source": [
    "y_pred = ann.predict(X_test)\n",
    "#np.set_printoptions(precision=2)\n",
    "print(np.concatenate((y_pred.reshape(len(y_pred),1), y_test.reshape(len(y_test),1)),1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qbS6rt7xZc2H"
   },
   "outputs": [],
   "source": [
    "\n",
    "df3 = pd.DataFrame(y_pred)\n",
    "df4 = pd.DataFrame(z_remaining)\n",
    "\n",
    "result_df1 = pd.concat([result_df,df3, df4], axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "N4CkiavwbUWn"
   },
   "outputs": [],
   "source": [
    "\n",
    "df5 = pd.DataFrame(time_remaining)\n",
    "\n",
    "result_df2 = pd.concat([result_df1, df5], axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9i2v5euVcO_I"
   },
   "outputs": [],
   "source": [
    "new_column_names = ['Actual Load', 'Prediction_LR', 'Prediction_ANN', 'Scheduled', 'Timestamps']\n",
    "\n",
    "result_df2.columns = new_column_names\n",
    "\n",
    "print(result_df2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XjJfknc6bh9o"
   },
   "outputs": [],
   "source": [
    "result_df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "l5j9hJbnak5E"
   },
   "outputs": [],
   "source": [
    "result_df2.to_csv('combined_data.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8iwgB9fMak8N"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zoJbweBNI7vY"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "# Plot original data and predictions\n",
    "# plt.plot(load, label='Original Load')\n",
    "plt.plot(y_pred, label=\"Predicted\" )\n",
    "plt.plot(y_test,color='red',label=\"Actual\")\n",
    "# plt.plot(np.arange(len(load), len(load)+n_steps), predictions, label='Predictions')\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('Load')\n",
    "plt.title('ANN Model Predictions for Load')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0dyaf1JOkE6O"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Define the start and end indices for the portion of data to plot\n",
    "start_index = 96*4\n",
    "end_index = 96*6\n",
    "\n",
    "# Plot selected portion of original data and predictions\n",
    "plt.plot(y_pred[start_index:end_index], label=\"Predicted\")\n",
    "plt.plot(y_test[start_index:end_index], color='red', label=\"Actual\")\n",
    "\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('Load')\n",
    "plt.title('ANN Model Predictions for Load for 2 days')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PhFxj2tXg1hd"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "print(\"Mean Squared Error:\", mse)\n",
    "print(\"R-squared:\", r2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LguYN-12cVQc"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def calculate_mape(y_true, y_pred):\n",
    "\n",
    "    y_true = np.array(y_true)\n",
    "    y_pred = np.array(y_pred)\n",
    "\n",
    "    ape = np.abs((y_true - y_pred) / y_true)\n",
    "\n",
    "    ape[np.isnan(ape)] = 0\n",
    "\n",
    "    mape = np.mean(ape) * 100\n",
    "\n",
    "    return mape\n",
    "\n",
    "mape = calculate_mape(y_test, y_pred)\n",
    "print(\"MAPE:\", mape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Hn0xFQX_dfH6"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def calculate_mae(y_true, y_pred):\n",
    "\n",
    "    y_true = np.array(y_true)\n",
    "    y_pred = np.array(y_pred)\n",
    "\n",
    "    absolute_errors = np.abs(y_true - y_pred)\n",
    "\n",
    "    mae = np.mean(absolute_errors)\n",
    "\n",
    "    return mae\n",
    "\n",
    "mae = calculate_mae(y_test, y_pred)\n",
    "print(\"MAE:\", mae)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8E2pHe-fMdNw"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "\n",
    "# Root Mean Squared Error (RMSE)\n",
    "rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "print(\"Root Mean Squared Error (RMSE):\", rmse)\n",
    "\n",
    "# Mean Absolute Percentage Error (MAPE)\n",
    "def mean_absolute_percentage_error(y_true, y_pred):\n",
    "    y_true, y_pred = np.array(y_true), np.array(y_pred)\n",
    "    return np.mean(np.abs((y_true - y_pred) / y_true)) * 100\n",
    "\n",
    "mape = mean_absolute_percentage_error(y_test, y_pred)\n",
    "print(\"Mean Absolute Percentage Error (MAPE):\", mape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3Euw-S25M7P4"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HtHAN_2qj3sP"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6SqUsjL5j3pe"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8h_9mHEjj3nV"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UTlr0dlKj3jp"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "X2uJ9uMcj3gk"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vEiosLGcj3cU"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lPGBpBxrj3Y9"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bFMtCKQuj3Uy"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0lgR1Fboj3HW"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "e3C_0J4D1Y31"
   },
   "outputs": [],
   "source": [
    "\n",
    "value = 13.676\n",
    "\n",
    "indices = np.where(load == value)\n",
    "\n",
    "print(\"Indices of value\", value, \":\", indices[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CPBTqeVF1Y51"
   },
   "outputs": [],
   "source": [
    "load[-193]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LuFEDTdj1ZCx"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "I3qMxbj31ZEv"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jJdlSWfu2W9O"
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "from statsmodels.tsa.stattools import adfuller\n",
    "\n",
    "def check_stationarity(series):\n",
    "    result = adfuller(series)\n",
    "\n",
    "    print('ADF Statistic: %f' % result[0])\n",
    "    print('p-value: %f' % result[1])\n",
    "    print('Critical Values:')\n",
    "    for key, value in result[4].items():\n",
    "        print('\\t%s: %.3f' % (key, value))\n",
    "\n",
    "    if (result[1] <= 0.05) & (result[4]['5%'] > result[0]):\n",
    "        print(\"\\u001b[32mStationary\\u001b[0m\")\n",
    "    else:\n",
    "        print(\"\\x1b[31mNon-stationary\\x1b[0m\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CxT6znHNfXEd"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "U0sD8Uo7JSCE"
   },
   "outputs": [],
   "source": [
    "check_stationarity(load)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "k2C2WYU3JSD2"
   },
   "outputs": [],
   "source": [
    "from statsmodels.graphics.tsaplots import plot_acf\n",
    "from statsmodels.graphics.tsaplots import plot_pacf\n",
    "import matplotlib.pyplot as plt\n",
    "width = 10\n",
    "height = 6\n",
    "lag_acf = 170\n",
    "lag_pacf = 170\n",
    "f, ax = plt.subplots(nrows=2, ncols=1, figsize=(width, 2*height))\n",
    "\n",
    "# Plot ACF\n",
    "plot_acf(load, lags=lag_acf, ax=ax[0])\n",
    "\n",
    "# Plot PACF\n",
    "plot_pacf(load, lags=lag_pacf, ax=ax[1], method='ols')\n",
    "\n",
    "ax[1].annotate('Strong correlation at lag = 1', xy=(1, 0.6), xycoords='data',\n",
    "               xytext=(0.17, 0.75), textcoords='axes fraction',\n",
    "               arrowprops=dict(color='red', shrink=0.05, width=1))\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7eNL65iCJSGa"
   },
   "outputs": [],
   "source": [
    "# Create subplots\n",
    "fig, (ax1, ax2) = plt.subplots(nrows=2, ncols=1, figsize=(10, 10))\n",
    "\n",
    "# Plot PACF on the first subplot\n",
    "plot_pacf(load, ax=ax1)\n",
    "ax1.set_title('Partial Autocorrelation Function (PACF)')\n",
    "\n",
    "# Plot ACF on the second subplot\n",
    "plot_acf(load, ax=ax2)\n",
    "ax2.set_title('Autocorrelation Function (ACF)')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "D-gLbZktPuJP"
   },
   "outputs": [],
   "source": [
    "load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "goLZeYHgJSLa"
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(load)\n",
    "plt.title('Load Data')\n",
    "plt.xlabel('Quarterly Time')\n",
    "plt.ylabel('Load in MW')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QVRMTEX1JSNf"
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(load[:700])  # Plotting the first 1000 data points\n",
    "plt.title('Load Data (First 1000 Data Points)')\n",
    "plt.xlabel('Quarterly Time')\n",
    "plt.ylabel('Load in MW')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "x4P7MV7mikFK"
   },
   "outputs": [],
   "source": [
    "\n",
    "# Assuming 'load' is your NumPy array containing time series data\n",
    "dates = pd.date_range(start='2022-01-01', periods=len(load), freq='15min')\n",
    "load_df = pd.DataFrame({'Value': load}, index=dates)\n",
    "\n",
    "# Convert index to DatetimeIndex\n",
    "load_df.index = pd.to_datetime(load_df.index)\n",
    "load_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oVeorkssmyvY"
   },
   "outputs": [],
   "source": [
    "from statsmodels.tsa.seasonal import seasonal_decompose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gfNR1XZOCNLX"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from statsmodels.tsa.seasonal import seasonal_decompose\n",
    "\n",
    "# Assuming 'load' is your time series data\n",
    "# Perform seasonal decomposition\n",
    "decomposition = seasonal_decompose(load, model='additive', period=12)  # Adjust period as needed\n",
    "\n",
    "# Plot the original time series and its components\n",
    "plt.figure(figsize=(12, 8))\n",
    "\n",
    "plt.subplot(411)\n",
    "plt.plot(load, label='Original')\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(412)\n",
    "plt.plot(decomposition.trend, label='Trend')\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(413)\n",
    "plt.plot(decomposition.seasonal, label='Seasonal')\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(414)\n",
    "plt.plot(decomposition.resid, label='Residual')\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "iGIEuXdlCd9v"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KVT1I0rpCd6w"
   },
   "outputs": [],
   "source": [
    "from statsmodels.tsa.seasonal import seasonal_decompose\n",
    "# Multiplicative Decomposition\n",
    "plt.figure(figsize=(12, 8))\n",
    "decomp_mul = seasonal_decompose(df['Load'], model='multiplicative', extrapolate_trend='freq', period=365)\n",
    "decomp_mul.plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DJC1bKydDHee"
   },
   "outputs": [],
   "source": [
    "from statsmodels.tsa.seasonal import seasonal_decompose\n",
    "# Multiplicative Decomposition\n",
    "decomp_mul = seasonal_decompose(df['Load'], model='additive', extrapolate_trend='freq', period=365)\n",
    "decomp_mul.plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EaEekBRLFNQM"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "eBVbWh4TFNN_"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gCkGyrLSFNLw"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8pDD0Wx3FNIi"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "n_grGkMwFNGX"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6K869hsxWK35"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BlDY9agXVeEd"
   },
   "source": [
    "Split dataset load into Train and Test:\n",
    "Testing for last 7 days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "K15kOREIVtv-"
   },
   "outputs": [],
   "source": [
    "train=load[:len(load)-100]\n",
    "test=load[len(load)-100:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ufShfzE4JSP2"
   },
   "outputs": [],
   "source": [
    "from statsmodels.tsa.ar_model import AutoReg\n",
    "\n",
    "# Fit AR model\n",
    "model = AutoReg(train, lags=8).fit() # Example: AR model with lag order 2\n",
    "print(model.summary())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pYCzzhimWYGX"
   },
   "outputs": [],
   "source": [
    "\n",
    "pred=model.predict(start=len(train),end=len(load)-1,dynamic=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3aI80389ZKd_"
   },
   "outputs": [],
   "source": [
    "comparison = pd.DataFrame({'Actual': test, 'Predicted': pred})\n",
    "print(comparison)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qYs6dZ8dSp7j"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "# Plot original data and predictions\n",
    "# plt.plot(load, label='Original Load')\n",
    "plt.plot(pred)\n",
    "plt.plot(test,color='red')\n",
    "# plt.plot(np.arange(len(load), len(load)+n_steps), predictions, label='Predictions')\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('Load')\n",
    "plt.title('AR Model Predictions for Load')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# Calculate RMSE (optional)\n",
    "# test_data = np.random.randn(n_steps)  # Example: test data\n",
    "rmse = np.sqrt(mean_squared_error(test, pred))\n",
    "print('Root Mean Squared Error (RMSE):', rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "aWuuVgI5ZyKT"
   },
   "outputs": [],
   "source": [
    "pred_future=model.predict(start=len(load)+1,end=len(load)+7,dynamic=False)\n",
    "print(pred_future)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "U_DQoKZyJSR8"
   },
   "outputs": [],
   "source": [
    "from statsmodels.tsa.arima.model import ARIMA\n",
    "# Fit a Moving Average (MA) model with order 1, discarding initial observations\n",
    "model = ARIMA(train, order=(0, 0, 5)).fit()  # ARIMA(p=0, d=0, q=1) for MA(1)\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "J6BbZHLEmgui"
   },
   "outputs": [],
   "source": [
    "predMA=model.predict(start=len(train),end=len(load)-1,dynamic=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Q6ve1uD4mqPp"
   },
   "outputs": [],
   "source": [
    "comparison = pd.DataFrame({'Actual': test, 'Predicted': predMA})\n",
    "print(comparison)\n",
    "from sklearn.metrics import mean_squared_error\n",
    "# Plot original data and predictions\n",
    "# plt.plot(load, label='Original Load')\n",
    "plt.plot(predMA)\n",
    "plt.plot(test,color='red')\n",
    "# plt.plot(np.arange(len(load), len(load)+n_steps), predictions, label='Predictions')\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('Load')\n",
    "plt.title('AR Model Predictions for Load')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# Calculate RMSE (optional)\n",
    "# test_data = np.random.randn(n_steps)  # Example: test data\n",
    "rmse = np.sqrt(mean_squared_error(test, predMA))\n",
    "print('Root Mean Squared Error (RMSE):', rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dX6U6ZTzniDK"
   },
   "outputs": [],
   "source": [
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xMnsL8NpoC_Q"
   },
   "outputs": [],
   "source": [
    "!pip install pmdarima"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EuTHk-Xqlv7U"
   },
   "outputs": [],
   "source": [
    "from pmdarima.arima import auto_arima"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Ir3RxcuWlv-C"
   },
   "outputs": [],
   "source": [
    "model_arima = auto_arima(train, seasonal=False, trace=True)\n",
    "\n",
    "# Print the summary of the best model\n",
    "print(model_arima.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IKv2utmalwAL"
   },
   "outputs": [],
   "source": [
    "from statsmodels.tsa.arima.model import ARIMA\n",
    "# Fit a Moving Average (MA) model with order 1, discarding initial observations\n",
    "modelARIMA = ARIMA(train, order=(5, 0, 5)).fit()  # ARIMA(p=0, d=0, q=1) for MA(1)\n",
    "print(modelARIMA.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dsgvK-F0lwCe"
   },
   "outputs": [],
   "source": [
    "predARIMA=modelARIMA.predict(start=len(train),end=len(load)-1,dynamic=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7dG7QNOFlwFQ"
   },
   "outputs": [],
   "source": [
    "comparison = pd.DataFrame({'Actual': test, 'Predicted': predARIMA})\n",
    "print(comparison)\n",
    "from sklearn.metrics import mean_squared_error\n",
    "# Plot original data and predictions\n",
    "# plt.plot(load, label='Original Load')\n",
    "plt.plot(test, label='Actual Load')  # Plot the actual load\n",
    "plt.plot(predARIMA, color='red', label='Predicted Load')  # Plot the predicted load\n",
    "# plt.plot(np.arange(len(load), len(load)+n_steps), predictions, label='Predictions')\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('Load')\n",
    "plt.title('AR Model Predictions for Load')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# Calculate RMSE (optional)\n",
    "# test_data = np.random.randn(n_steps)  # Example: test data\n",
    "rmse = np.sqrt(mean_squared_error(test, predARIMA))\n",
    "print('Root Mean Squared Error (RMSE):', rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XzK2cG5uEani"
   },
   "outputs": [],
   "source": [
    "model_arima = auto_arima(train, seasonal=False,start_p=1, d=0, start_q=1,  # Lower values for p and q\n",
    "                         max_p=5, max_q=5,              # Upper limit for p and q\n",
    "                         information_criterion='aic',   # Prioritize faster model selection\n",
    "                          trace=True)\n",
    "\n",
    "# Print the summary of the best model\n",
    "print(model_arima.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nCYB__dvDddI"
   },
   "outputs": [],
   "source": [
    "from statsmodels.tsa.arima.model import ARIMA\n",
    "# Fit a Moving Average (MA) model with order 1, discarding initial observations\n",
    "modelARIMA = ARIMA(train, order=(5, 0, 5)).fit()  # ARIMA(p=0, d=0, q=1) for MA(1)\n",
    "print(modelARIMA.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SHFHXdI4Jdse"
   },
   "outputs": [],
   "source": [
    "predARIMA=modelARIMA.predict(start=len(train),end=len(load)-1,dynamic=False)\n",
    "comparison = pd.DataFrame({'Actual': test, 'Predicted': predARIMA})\n",
    "print(comparison)\n",
    "from sklearn.metrics import mean_squared_error\n",
    "plt.plot(test, label='Actual Load')  # Plot the actual load\n",
    "plt.plot(predARIMA, color='red', label='Predicted Load')  # Plot the predicted load\n",
    "# plt.plot(np.arange(len(load), len(load)+n_steps), predictions, label='Predictions')\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('Load')\n",
    "plt.title('AR Model Predictions for Load')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "rmse = np.sqrt(mean_squared_error(test, predARIMA))\n",
    "print('Root Mean Squared Error (RMSE):', rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NHQO4SLdJraV"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
